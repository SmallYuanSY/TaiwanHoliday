#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¬è©¦çˆ¬èŸ²è…³æœ¬ - ç”¨æ–¼é©—è­‰ç¶²é è§£æåŠŸèƒ½
"""

from taiwan_holiday_crawler import TaiwanHolidayCrawler
import logging

# è¨­å®šæ—¥èªŒç­‰ç´šç‚ºDEBUGä»¥é¡¯ç¤ºæ›´å¤šè³‡è¨Š
logging.basicConfig(level=logging.DEBUG)

def test_crawler():
    """æ¸¬è©¦çˆ¬èŸ²çš„åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ” é–‹å§‹æ¸¬è©¦å°ç£æ”¿åºœè¾¦å…¬æ—¥æ›†è¡¨çˆ¬èŸ²...")
    
    crawler = TaiwanHolidayCrawler()
    
    # æ¸¬è©¦ç²å–å¯ç”¨å¹´ä»½å’Œé€£çµ
    print("\nğŸ“… æ¸¬è©¦ç²å–å¯ç”¨å¹´ä»½å’Œä¸‹è¼‰é€£çµ...")
    available_data = crawler.get_available_years_and_urls()
    
    if available_data:
        print(f"âœ… æˆåŠŸæ‰¾åˆ° {len(available_data)} å€‹å¹´ä»½çš„è³‡æ–™:")
        for year, url in sorted(available_data.items()):
            print(f"  ğŸ“Š {year} å¹´: {url[:100]}...")
            
            # æ¸¬è©¦é€£çµé©—è­‰
            is_valid = crawler.validate_csv_url(year, url)
            print(f"     é©—è­‰çµæœ: {'âœ… æœ‰æ•ˆ' if is_valid else 'âŒ ç„¡æ•ˆ'}")
    else:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„è³‡æ–™é€£çµ")
    
    # æ¸¬è©¦ç›®æ¨™å¹´ä»½
    print("\nğŸ¯ æ¸¬è©¦ç›®æ¨™å¹´ä»½è¨­å®š...")
    target_years = crawler.get_target_years()
    print(f"ç›®æ¨™å¹´ä»½: {target_years}")
    
    # æª¢æŸ¥ç›®æ¨™å¹´ä»½æ˜¯å¦æœ‰å¯ç”¨è³‡æ–™
    for year in target_years:
        if year in available_data:
            print(f"âœ… {year} å¹´æœ‰å¯ç”¨è³‡æ–™")
        else:
            print(f"âš ï¸  {year} å¹´æš«ç„¡å¯ç”¨è³‡æ–™")
    
    print("\nğŸ”¬ æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    test_crawler() 